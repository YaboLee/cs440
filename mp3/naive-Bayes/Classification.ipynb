{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DATA():\n",
    "    def __init__(self, matrix, label):\n",
    "        self.matrix = matrix\n",
    "        self.label = label   \n",
    "        self.feature = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_data(source, classified):\n",
    "    if classified:\n",
    "        digits_data = {}\n",
    "    else:\n",
    "        digits_data = []\n",
    "        \n",
    "    with open(source) as f:\n",
    "        matrix = []\n",
    "        vector = []\n",
    "        for line in f:\n",
    "            if len(line) > 10:\n",
    "                for element in line.rstrip():  \n",
    "                    vector.append(int(element))\n",
    "                matrix.append(line.rstrip())\n",
    "            else:\n",
    "                class_idx = int(line.rstrip())\n",
    "                observation = DATA(matrix, class_idx)\n",
    "                observation.feature = np.array(vector)\n",
    "                \n",
    "                if classified:\n",
    "                    if class_idx not in digits_data:\n",
    "                        digits_data[class_idx] = [observation]\n",
    "                    else:\n",
    "                        digits_data[class_idx] = digits_data[class_idx] + [observation]\n",
    "                    matrix = []\n",
    "                    vector = []    \n",
    "                else:\n",
    "                    digits_data.append(observation)\n",
    "                    matrix = []\n",
    "                    vector = []\n",
    "                    \n",
    "    return digits_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_prior(trn_data):\n",
    "    prior = {}\n",
    "    total = 0\n",
    "    for i in range(10):\n",
    "        total += len(trn_data[i])\n",
    "    for i in range(10):\n",
    "        prior[i] = len(trn_data[i]) / total\n",
    "    return prior \n",
    "\n",
    "def likelihood(trn_data, target):\n",
    "    feature_dict = {}\n",
    "    for i in range(10):\n",
    "        feature_dict[i] = np.zeros((32, 32))       \n",
    "    for class_idx in range(10):\n",
    "        digit_data = trn_data[class_idx]\n",
    "        feature_prob = feature_dict[class_idx] \n",
    "        for i in range(32):\n",
    "            for j in range(32): \n",
    "                f = 0\n",
    "                num = 0\n",
    "                for digit in digit_data:\n",
    "                    if digit.matrix[i][j] == target:\n",
    "                        f += 1\n",
    "                    num += 1\n",
    "                # Laplace Smoothing\n",
    "                feature_prob[i][j] = (f+1)/(num+1)\n",
    "                \n",
    "    return feature_dict\n",
    "\n",
    "def prediction(tst_data, prior, feature_dict_0, feature_dict_1):\n",
    "    pred_label = {}\n",
    "    for idx in range(10):\n",
    "        digits_data = tst_data[idx]\n",
    "        label = []\n",
    "        for digit in digits_data:\n",
    "            prob = np.zeros((10,))\n",
    "            for class_idx in range(10):\n",
    "                feature_class_1 = feature_dict_1[class_idx]\n",
    "                feature_class_0 = feature_dict_0[class_idx]\n",
    "                log_sum = np.log(prior[class_idx])\n",
    "                for i in range(32):\n",
    "                    for j in range(32):\n",
    "                        if digit.matrix[i][j] == \"0\":\n",
    "                            log_sum += np.log(feature_class_0[i][j])\n",
    "                        else:\n",
    "                            log_sum += np.log(feature_class_1[i][j])\n",
    "\n",
    "                prob[class_idx] = log_sum\n",
    "                \n",
    "            label.append(int(np.argmax(prob)))\n",
    "        pred_label[idx] = label\n",
    "    return pred_label\n",
    "\n",
    "def cor_rate(actual, predict):\n",
    "    sum = 0\n",
    "    for value in predict:\n",
    "        if value == actual:\n",
    "            sum += 1\n",
    "    return sum / len(predict)\n",
    "\n",
    "def correct_rate(pred_label):\n",
    "    rate = np.zeros((10,))\n",
    "    for i in range(10):\n",
    "        rate[i] = cor_rate(i, pred_label[i])\n",
    "    return rate\n",
    "\n",
    "def correct_rate_overall(pred_label):\n",
    "    hit = 0\n",
    "    total = 0\n",
    "    for i in range(10):\n",
    "        for label in pred_label[i]:\n",
    "            if label == i:\n",
    "                hit += 1\n",
    "            total += 1\n",
    "    return hit / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trn_data = import_data(\"optdigits-orig_train.txt\", True)\n",
    "tst_data = import_data(\"optdigits-orig_test.txt\", True)\n",
    "prior = eval_prior(trn_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.1: _Naive Bayes Classifier:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict_0 = likelihood(trn_data, \"0\")\n",
    "feature_dict_1 = likelihood(trn_data, \"1\")\n",
    "pred_label = prediction(tst_data, prior, feature_dict_0, feature_dict_1)\n",
    "\n",
    "correct_rate(pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2.1: _Perceptron:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the multi-class (non-differentiable) perceptron learning rule from lecture to the digit classification problem from Part 1.1. As before, the basic feature set consists of a single binary indicator feature for each pixel. Specifically, the feature $F_{i,j}$ indicates the status of the (i,j)-th pixel. Its value is 1 if the pixel contains value 1, and 0 if it is 0. The images are of size 32*32, so there are 1024 features in total. For a multi-class perceptron, you need to learn a weight vector for each digit class. Each component of a weight vector corresponds to the weight of a pixel, which makes it of length either 1024 (without bias) or 1025 (with bias)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get your results, you should tune the following parameters (it is not necessary to separately report results for multiple settings, only report which options you tried and which one worked the best):\n",
    "\n",
    "- Learning rate decay function;\n",
    "- Bias vs. no bias;\n",
    "- Initialization of weights (zeros vs. random);\n",
    "- Ordering of training examples (fixed vs. random);\n",
    "- Number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import random\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def prediction_p(tst_data, w):\n",
    "    pred = {}\n",
    "    for class_idx in range(10):\n",
    "        tst_data_i = tst_data[class_idx]\n",
    "        label = []\n",
    "        for data in tst_data_i:\n",
    "            c = np.zeros((10,))\n",
    "            for i in range(10):\n",
    "                c[i] = data.feature @ w[i]\n",
    "            label.append(int(np.argmax(c)))\n",
    "        pred[class_idx] = label \n",
    "        \n",
    "    return pred\n",
    "\n",
    "def rate_helper(actual, predict):\n",
    "    sum = 0\n",
    "    for value in predict:\n",
    "        if value == actual:\n",
    "            sum += 1\n",
    "    return sum / len(predict)\n",
    "\n",
    "def correct_rate(pred_label):\n",
    "    rate = np.zeros((10,))\n",
    "    for i in range(10):\n",
    "        rate[i] = rate_helper(i, pred_label[i])\n",
    "    return rate\n",
    "\n",
    "def correct_rate_overall(pred_label):\n",
    "    hit = 0\n",
    "    total = 0\n",
    "    for i in range(10):\n",
    "        for label in pred_label[i]:\n",
    "            if label == i:\n",
    "                hit += 1\n",
    "            total += 1\n",
    "    return hit / total\n",
    "\n",
    "# This is a 10x10 matrix whose entry in row r and column c is \n",
    "# the percentage of test images from class r that are classified as class c\n",
    "def confusion_matrix(pred_label):\n",
    "    confusion = np.zeros((10, 10))\n",
    "    for r in range(10):\n",
    "        class_r = pred_label[r]\n",
    "        num_cor = np.zeros((10,))\n",
    "        total = 0\n",
    "        for label in class_r:\n",
    "            num_cor[label] += 1\n",
    "            total += 1\n",
    "        confusion[r] = num_cor / total\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import overall training data\n",
    "trn_data_unclassified = import_data(\"optdigits-orig_train.txt\", classified = False)\n",
    "trn_data = import_data(\"optdigits-orig_train.txt\", classified = True)\n",
    "tst_data = import_data(\"optdigits-orig_test.txt\", classified = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _**Implementing the Perceptron:**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(trn_data_unclassified, trn_data, epochs, bias, random_ordering, w):\n",
    "    results = {}\n",
    "    # Start:\n",
    "    for n in range(epochs):\n",
    "        train_data = trn_data_unclassified[:]\n",
    "        if random_ordering:\n",
    "            random.shuffle(train_data)\n",
    "\n",
    "        for idx, digit in enumerate(train_data):\n",
    "            eta = 1 / (0.01 * idx + 1) # Learning rate decay function\n",
    "\n",
    "            for class_idx in range(10):\n",
    "                if digit.label == class_idx:\n",
    "                    y = 1\n",
    "                else:\n",
    "                    y = -1\n",
    "                if (digit.feature @ w[class_idx] + bias) * y <= 0:\n",
    "                    w[class_idx] = w[class_idx] + eta * y * digit.feature\n",
    "\n",
    "        pred = prediction_p(trn_data, w)\n",
    "        rate_overall = correct_rate_overall(pred)\n",
    "        results[n+1] = rate_overall\n",
    "        if rate_overall == 1:\n",
    "            return results\n",
    "\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _**Setting the Tuning Parameters and start learning**_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Test Accuracy: 0.9504504504504504\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1.     0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.9778 0.     0.     0.     0.     0.     0.0222 0.     0.    ]\n",
      " [0.     0.     0.8537 0.     0.     0.     0.     0.     0.122  0.0244]\n",
      " [0.     0.     0.     0.9697 0.     0.     0.     0.     0.     0.0303]\n",
      " [0.     0.0339 0.     0.     0.9153 0.     0.     0.     0.0339 0.0169]\n",
      " [0.     0.     0.     0.     0.     1.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.0233 0.     0.9535 0.     0.0233 0.    ]\n",
      " [0.     0.     0.     0.     0.0213 0.     0.     0.9787 0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.025  0.     0.     0.975  0.    ]\n",
      " [0.0238 0.     0.0238 0.     0.     0.0238 0.     0.0238 0.0238 0.881 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bb488d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#w = np.zeros((10, 1024))\n",
    "w = np.random.rand(10, 1024)\n",
    "epochs = 50\n",
    "bias = 0\n",
    "random_ordering = True\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "results = perceptron(trn_data_unclassified, trn_data, epochs, bias, random_ordering, w)\n",
    "pred = prediction_p(tst_data, w)\n",
    "rate_overall = correct_rate_overall(pred)\n",
    "confusion = confusion_matrix(pred)\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "print(\"Overall Test Accuracy: {}\\n\".format(rate_overall))\n",
    "print(\"Confusion Matrix:\")\n",
    "np.set_printoptions(precision=4)\n",
    "print(confusion)\n",
    "\n",
    "n_epochs = list(results.keys())\n",
    "trn_correct_rate = list(results.values())\n",
    "plt.xlabel('number of epochs')\n",
    "plt.ylabel('overall train correction rate')\n",
    "plt.title('epochs vs performance')\n",
    "plt.plot(n_epochs, trn_correct_rate, 'bo-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- _**Discussion:**_\n",
    "\n",
    "    - From the above code, it seems that when the ordering is random, bias doesn't really matter. Here we set bias = 0.\n",
    "    - The decay training function is: $\\eta = \\frac{1}{0.001 * n + 1}$ with nth sample and decay rate 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
