{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DATA():\n",
    "    def __init__(self, matrix, label):\n",
    "        self.matrix = matrix\n",
    "        self.label = label   \n",
    "        self.feature = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_data(source, classified):\n",
    "    if classified:\n",
    "        digits_data = {}\n",
    "    else:\n",
    "        digits_data = []\n",
    "        \n",
    "    with open(source) as f:\n",
    "        matrix = []\n",
    "        vector = []\n",
    "        for line in f:\n",
    "            if len(line) > 10:\n",
    "                for element in line.rstrip():  \n",
    "                    vector.append(int(element))\n",
    "                matrix.append(line.rstrip())\n",
    "            else:\n",
    "                class_idx = int(line.rstrip())\n",
    "                observation = DATA(matrix, class_idx)\n",
    "                observation.feature = np.array(vector)\n",
    "                \n",
    "                if classified:\n",
    "                    if class_idx not in digits_data:\n",
    "                        digits_data[class_idx] = [observation]\n",
    "                    else:\n",
    "                        digits_data[class_idx] = digits_data[class_idx] + [observation]\n",
    "                    matrix = []\n",
    "                    vector = []    \n",
    "                else:\n",
    "                    digits_data.append(observation)\n",
    "                    matrix = []\n",
    "                    vector = []\n",
    "                    \n",
    "    return digits_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_prior(trn_data):\n",
    "    prior = {}\n",
    "    total = 0\n",
    "    for i in range(10):\n",
    "        total += len(trn_data[i])\n",
    "    for i in range(10):\n",
    "        prior[i] = len(trn_data[i]) / total\n",
    "    return prior \n",
    "\n",
    "def likelihood(trn_data, target):\n",
    "    feature_dict = {}\n",
    "    for i in range(10):\n",
    "        feature_dict[i] = np.zeros((32, 32))       \n",
    "    for class_idx in range(10):\n",
    "        digit_data = trn_data[class_idx]\n",
    "        feature_prob = feature_dict[class_idx] \n",
    "        for i in range(32):\n",
    "            for j in range(32): \n",
    "                f = 0\n",
    "                num = 0\n",
    "                for digit in digit_data:\n",
    "                    if digit.matrix[i][j] == target:\n",
    "                        f += 1\n",
    "                    num += 1\n",
    "                # Laplace Smoothing\n",
    "                feature_prob[i][j] = (f+1)/(num+1)\n",
    "                \n",
    "    return feature_dict\n",
    "\n",
    "def prediction(tst_data, prior, feature_dict_0, feature_dict_1):\n",
    "    pred_label = {}\n",
    "    for idx in range(10):\n",
    "        digits_data = tst_data[idx]\n",
    "        label = []\n",
    "        for digit in digits_data:\n",
    "            prob = np.zeros((10,))\n",
    "            for class_idx in range(10):\n",
    "                feature_class_1 = feature_dict_1[class_idx]\n",
    "                feature_class_0 = feature_dict_0[class_idx]\n",
    "                log_sum = np.log(prior[class_idx])\n",
    "                for i in range(32):\n",
    "                    for j in range(32):\n",
    "                        if digit.matrix[i][j] == \"0\":\n",
    "                            log_sum += np.log(feature_class_0[i][j])\n",
    "                        else:\n",
    "                            log_sum += np.log(feature_class_1[i][j])\n",
    "\n",
    "                prob[class_idx] = log_sum\n",
    "                \n",
    "            label.append(int(np.argmax(prob)))\n",
    "        pred_label[idx] = label\n",
    "    return pred_label\n",
    "\n",
    "def cor_rate(actual, predict):\n",
    "    sum = 0\n",
    "    for value in predict:\n",
    "        if value == actual:\n",
    "            sum += 1\n",
    "    return sum / len(predict)\n",
    "\n",
    "def correct_rate(pred_label):\n",
    "    rate = np.zeros((10,))\n",
    "    for i in range(10):\n",
    "        rate[i] = cor_rate(i, pred_label[i])\n",
    "    return rate\n",
    "\n",
    "def correct_rate_overall(pred_label):\n",
    "    hit = 0\n",
    "    total = 0\n",
    "    for i in range(10):\n",
    "        for label in pred_label[i]:\n",
    "            if label == i:\n",
    "                hit += 1\n",
    "            total += 1\n",
    "    return hit / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trn_data = import_data(\"optdigits-orig_train.txt\", True)\n",
    "tst_data = import_data(\"optdigits-orig_test.txt\", True)\n",
    "prior = eval_prior(trn_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.1: _Naive Bayes Classifier:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97222222, 0.93333333, 0.85365854, 0.90909091, 0.88135593,\n",
       "       0.93103448, 0.97674419, 0.9787234 , 1.        , 0.92857143])"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dict_0 = likelihood(trn_data, \"0\")\n",
    "feature_dict_1 = likelihood(trn_data, \"1\")\n",
    "pred_label = prediction(tst_data, prior, feature_dict_0, feature_dict_1)\n",
    "\n",
    "correct_rate(pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2.1: _Perceptron:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the multi-class (non-differentiable) perceptron learning rule from lecture to the digit classification problem from Part 1.1. As before, the basic feature set consists of a single binary indicator feature for each pixel. Specifically, the feature $F_{i,j}$ indicates the status of the (i,j)-th pixel. Its value is 1 if the pixel contains value 1, and 0 if it is 0. The images are of size 32*32, so there are 1024 features in total. For a multi-class perceptron, you need to learn a weight vector for each digit class. Each component of a weight vector corresponds to the weight of a pixel, which makes it of length either 1024 (without bias) or 1025 (with bias)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get your results, you should tune the following parameters (it is not necessary to separately report results for multiple settings, only report which options you tried and which one worked the best):\n",
    "\n",
    "- Learning rate decay function;\n",
    "- Bias vs. no bias;\n",
    "- Initialization of weights (zeros vs. random);\n",
    "- Ordering of training examples (fixed vs. random);\n",
    "- Number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import random\n",
    "\n",
    "def prediction(tst_data, w):\n",
    "    pred = {}\n",
    "    for class_idx in range(10):\n",
    "        tst_data_i = tst_data[class_idx]\n",
    "        label = []\n",
    "        for data in tst_data_i:\n",
    "            c = np.zeros((10,))\n",
    "            for i in range(10):\n",
    "                c[i] = data.feature @ w[i]\n",
    "            label.append(int(np.argmax(c)))\n",
    "        pred[class_idx] = label \n",
    "        \n",
    "    return pred\n",
    "\n",
    "def cor_rate(actual, predict):\n",
    "    sum = 0\n",
    "    for value in predict:\n",
    "        if value == actual:\n",
    "            sum += 1\n",
    "    return sum / len(predict)\n",
    "\n",
    "def correct_rate(pred_label):\n",
    "    rate = np.zeros((10,))\n",
    "    for i in range(10):\n",
    "        rate[i] = cor_rate(i, pred_label[i])\n",
    "    return rate\n",
    "\n",
    "def correct_rate_overall(pred_label):\n",
    "    hit = 0\n",
    "    total = 0\n",
    "    for i in range(10):\n",
    "        for label in pred_label[i]:\n",
    "            if label == i:\n",
    "                hit += 1\n",
    "            total += 1\n",
    "    return hit / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import overall training data\n",
    "trn_data_unclassified = import_data(\"optdigits-orig_train.txt\", classified = False)\n",
    "trn_data = import_data(\"optdigits-orig_train.txt\", True)\n",
    "tst_data = import_data(\"optdigits-orig_test.txt\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _**Implementing the Perceptron:**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9481981981981982"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "# Tuning Parameters:\n",
    "w = np.zeros((10, 1024))\n",
    "#w = np.random.rand(10, 1024)\n",
    "\n",
    "epochs = 10\n",
    "bias = 500\n",
    "random_ordering = True\n",
    "\n",
    "# Start:\n",
    "for n in range(epochs):\n",
    "    train_data = trn_data_unclassified[:]\n",
    "    if random_ordering:\n",
    "        random.shuffle(train_data)\n",
    "    \n",
    "    for idx, digit in enumerate(train_data):\n",
    "        eta = 1 / (0.05 * idx + 1) # Learning rate decay function\n",
    "        \n",
    "        for class_idx in range(10):\n",
    "            if digit.label == class_idx:\n",
    "                y = 1\n",
    "            else:\n",
    "                y = -1\n",
    "            if (digit.feature @ w[class_idx] + bias) * y <= 0:\n",
    "                w[class_idx] = w[class_idx] + eta * y * digit.feature\n",
    "    \n",
    "    pred = prediction(trn_data, w)\n",
    "    rate_overall = correct_rate_overall(pred)\n",
    "    results[n] = rate_overall\n",
    "\n",
    "    \n",
    "# Get predicted label for each test data\n",
    "pred = prediction(tst_data, w)\n",
    "\n",
    "# Get correction rate\n",
    "correct_rate_overall(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9351395730706076,\n",
       " 1: 0.9330870279146142,\n",
       " 2: 0.9421182266009852,\n",
       " 3: 0.9466338259441708,\n",
       " 4: 0.9490968801313628,\n",
       " 5: 0.9573070607553367,\n",
       " 6: 0.9610016420361248,\n",
       " 7: 0.9601806239737274,\n",
       " 8: 0.9642857142857143,\n",
       " 9: 0.9679802955665024}"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _**Get predicted label and calculate correction rate**_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35468167, 0.27812407, 0.67124813, ..., 0.1138031 , 0.06116693,\n",
       "       0.53499403])"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.random.rand(10, 1024)\n",
    "\n",
    "w[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 5\n",
    "# print(\"Label:\", trn_data[i].label)\n",
    "# trn_data[i].matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialization of weights zero\n",
    "# w = np.zeros((10,1024))\n",
    "\n",
    "# w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # eta = 1/n\n",
    "# def learning_rate(n):\n",
    "#     return 1/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def perceptron(epochs, w, bias, ordering, trn_data):\n",
    "#     # For each digits training class\n",
    "#     for i in range(10):\n",
    "#         w_i = w[i]\n",
    "#         trn_data_i = trn_data[i]\n",
    "        \n",
    "#         for n in range(epochs):\n",
    "#             eta = learning_rate(n+1)\n",
    "#             cur_digit = trn_data_i[n]\n",
    "#             if cur_digit.feature @ w_i + bias <= 0:\n",
    "#                 w = w + eta * cur_digit.feature_vector\n",
    "    \n",
    "#     epochs = 0\n",
    "#     eta = learning_rate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.rand(10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
